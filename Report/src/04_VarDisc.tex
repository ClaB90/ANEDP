%\chapter{Discretizzazione variazionale}
\section{Discretizzazione variazionale}
\label{chap:DiscVar}
Per approssimare il problema di controllo ottimo [P] viene applicato un metodo detto di discretizzazione variazionale, introdotto da M. Hinze in [Hin05]. Nella prossima sezione viene brevemente presentato questo metodo nel caso generale di problemi di controllo quadratici, dopodiché lo si vedrà in azione per  la risoluzione di \ref{eq:200}.   


\subsection{Il caso generale}

Si consideri il seguente problema di controllo ottimo quadratico
\begin{equation}
\label{controlpb}
\min_{(y,u)\in Y\times U} J(y,u)   \ \text{s.t.} \ y=Su \  \text{and} \ u\in U_{ad},
\end{equation}
dove $ U=U^*$ denota lo spazio di Hilbert del controllo, $ Y $ lo spazio di Banach dello stato, $ S:U\to Y\subseteq U $ l'operatore lineare e limitato tra controllo e stato, e $ U_{ad}\subseteq U $ l'insieme chiuso e convesso dei controlli ammissibili. Inoltre per $ \alpha>0 $ sia il funzionale $ J $ dato da 
\begin{equation}
J(y,u)=\frac{1}{2}\norma{y-z}^2_Z + \frac{\alpha}{2}\norma{u}^2_U,
\end{equation}
dove $ Z=Z^* $ denota uno spazio di Hilbert, $ z\in Z $ e $ Y\hookrightarrow Z\hookrightarrow Y^* $.   

La presente  discretizzazione di ~\eqref{controlpb} si basa sulla discretizzazione dei soli spazi di stato e aggiunto, utilizzando implicitamente le condizioni di ottimalità del primo ordine per la discretizzazione del controllo. Tra i vantaggi di tale approccio si consideri , nel caso si utilizzino schemi ad elementi finiti,  il disaccoppiamento dell'approssimazione dell'\textit{active set} dai nodi della griglia per gli EF. 

Per definire il controllo discreto sia $ S_h:U\to Y_h\subset Y\subseteq U$ l'operatore lineare limitato tra il controllo e lo stato discretizzato, dove $ Y_h\subseteq Y $ è uno sottospazio finito-dimensionale equipaggiato con la norma di $ Y $.
\begin{definizione}

$ u^*_h\in U_{ad} $ è detto controllo discreto ottimale $ \iff $
\begin{equation}
\label{contrpbdisc}
\big( \hat{J}'_h(u^*_h),v-u^*_h\big)_U \ge 0 \ \forall v\in U_{ad},
\end{equation}
dove $ \hat{J}'_h(u):=J(S_h u,u) $.
\end{definizione}
\begin{osservazione}

Nel caso di problemi di controllo quadratici vincolati (come per il presente lavoro) la disuguaglianza variazionale ~\eqref{contrpbdisc} è condizione di ottimalità necessaria e sufficiente di 
\begin{equation}
u^{*}_{h}= \argmin_{u \in U_{ad}} J(S_hu,u).
\end{equation}

\end{osservazione}.
Se esprimiamo la condizione di ottimalità ~\eqref{contrpbdisc} qualora $ U_{ad}=U $ appare chiaro come sia possibile realizzare uno schema numerico per risolvere un problema di ottimizzazione senza discretizzare lo spazio di controllo:
\begin{equation}
u^*_h=\frac{-1}{\alpha}S^*_h(S_hu^*_h-z),
\end{equation}
Infatti, sebbene $ u^*_h $ sia in $ U $, esso è implicitamente un oggetto discreto per via dell'operatore aggiunto discreto.

Ora si riporta senza dimostrazione il risultato principale legato alla discretizzazione variazionale, che poi sarà utile in seguito: 
\begin{teorema}
\label{teo:Hin}

Se gli operatori $ S_h, S^*_h $ soddisfano le condizioni
\begin{itemize}

\item $ \norma{(S^*-S^*_h)z}_U\le Ch^2\norma{z}_Z $
\item $ \norma{(S^*S-S^*_hS_h)u^*}_U\le Ch^2\norma{u^*}_U $

\end{itemize}
allora per $ h>0 $ sufficientemente piccolo la disuguaglianza variazionale ~\eqref{contrpbdisc} ammette un'unica soluzione $ u^*_h\in U_{ad} $ che soddisfa 
\begin{equation}
\norma{u^*-u^*_h}_U\le Ch^2\{ \norma{u^*}_U + \norma{z}_Z\}.
\end{equation}
Qui, $ u^*\in U_{ad} $ denota l'unica soluzione del problema ~\eqref{controlpb}.

\end{teorema}

\subsection{Il caso in oggetto}

Ora si vuole applicare il metodo di discretizzazione variazionale al problema [RIF] nei confronti della variabile tempo, dove gli operatori $ S_h $ e $ S^*_h $ sono individuati dagli schemi di Petrov-Galerkin esposti nei capitoli precedenti.

Dunque, il problema (semi)discretizzato da considerare è
\begin{gather}
\label{Pk}
\min_{y_k\in Y_k, u\in U_{ad}} J(y_k,u)=\frac{1}{2}\norma{y_k-y_d}^2_{L^2(I,L^2(\Omega))} + \frac{\alpha}{2}\norma{u}^2_U, \\
\text{s.t.} \ y_k=S_k(Bu,y_0),
\end{gather}
dove $ S_k $ è l'operatore delle soluzioni associato a [RIF]. Grazie ai risultati della precedente sezione questo problema ammette un'unica soluzione $ (\bar{y}_k, \bar{u}_k)\in Y_k\times U_{ad} $, con $ \bar{y}_k=S_k(B\bar{u}_k,y_0) $ e la condizione di ottimalità del primo ordine recita
\begin{equation}
\label{cnott}
\bar{u}_k=P_{U_{ad}}\big( -\frac{1}{\alpha}B'\bar{p}_k\big),
\end{equation}
dove $ \bar{p}_k\in P_k $ denota la variabile aggiunta discreta, che è l'unica soluzione di [RIF] con $ h:=\bar{y}_k-y_d $.
A partire dalla formulazione del problema ~\eqref{P_k} è possibile ottenere delle stime di convergenza che somigliano alla stima standard ottenuta per problemi con discretizzazione variazionale. Per completezza vengono trascritti qui di seguito tali risultati.
\begin{teorema}
\label{convu}

Siano $ \bar{u} $ e $ \bar{u}_k $ le soluzioni di [RIF]  e di ~\eqref{Pk} rispettivamente. Allora
\begin{multline} 
\alpha \lvert \bar{u}_k-\bar{u}\rvert_I\le Ck^2\big( \norma{\bar{u}}_{H^1(I,\R^D)} + \norma{\bar{u}(0)}_{\R^D} + \\
\norma{y_d}_{H^1(I,L^2(\Omega))} + \norma{y_d(T)}_{H^1(\Omega)} + \norma{y_0}_{H^1(\Omega)} + \norma{\Delta y_0}_{H^1(\Omega)}\big)
\end{multline}
è soddisfatta.

\end{teorema}

\begin{teorema}
\label{convy}

Siano $ \bar{u} $ e $ \bar{u}_k $ le soluzioni di [RIF] e~\eqref{Pk} rispettivamente. Allora vale
\begin{multline}
\norma{\bar{y}-\pi_{P^*_k}\bar{y_k}}_I\le\big( \lvert a\rvert_I + \norma{\bar{u}}_{H^1(I,\R^D)} + \norma{\bar{u}(0)}_{\R^D} + \\ 
\norma{y_d}_{H^1(I,L^2(\Omega))} + \norma{y_d(T)}_{H^1(\Omega)} + \norma{y_0}_{H^1(\Omega)} + \norma{\Delta y_0}_{H^1(\Omega)}\big).
\end{multline}

\end{teorema}  

\section{Metodo di punto fisso}

L'equazione ~\eqref{cnott} è incline ad essere risolta numericamente nonostante il controllo non sia discretizzato esplicitamente; nel presente lavoro vengono scelti schemi di punto fisso e Newton con damping (semi-Newton).

Per quanto riguarda il metodo di punto fisso, se si indica con $ S^*_h $ l'operatore di soluzione dell'equazione [RIF], l'algoritmo è il seguente:
\begin{algoritmo}

\begin{enumerate}
\item Inizializzare $ u^0_h\in U_{ad} $, $ n:=0 $.
\item Ripetere fino a convergenza
          \begin{enumerate}
          \item calcolare $ Bu^n_h $,
          \item calcolare $ y^n_h=S_h(y_0,Bu^n_h) $, 
          \item calcolare $ p^n_h=S^*_h(y^n_h-y_d) $,
          \item calcolare $ u^{n+1}_h=P_{U_{ad}}\big( -\frac{1}{\alpha}B'p^n_h\big) $,
          \item porre n=n+1.
          \end{enumerate}
\end{enumerate}

Come criterio di arresto è stato scelto   
\begin{equation}
\norma{B'\big(p^{n+1}_h-p^n_h\big)}_{L^{\infty}(\Omega\times I)}<\epsilon,
\label{eq:PuntoFissotoll}
\end{equation}
con $ \epsilon $ tolleranza prefissata.
\label{PuntoFisso}
\end{algoritmo}

Seguendo [RIF] il metodo di punto fisso per l'equazione ~\eqref{cnott} converge globalmente per $ \alpha>\norma{S_h}^2_{\mathcal{L}(L^2(\Omega),L^2(\Omega))} $, motivo per cui è stato implementato anche lo schema semi-Newton, che ha invece la pretesa di convergere globalmente per qualsiasi valore di $ \alpha $.

\section{Metodo semi-Newton}
Affinché il metodo di Newton converga globalmente, è stato scelto di applicare ad ogni passo una minimizzazione monodimensionale con criterio di Armijo; per ottenere ciò è opportuno riformulare ~\eqref{Pk} come problema di minimizzazione non vincolata; ci si basa dunque sulla seguente funzione lagrangiana duale $ \phi:L^2(I,L^2(\Omega))\to \R $ data da
\begin{multline}
\label{lagr}
\phi(w)= \\
-\inf_{u,y\in L^2(I,L^2(\Omega))}\Biggl( \underbrace{\frac{1}{2}\norma{y-y_d}^2_{L^2(I,L^2(\Omega))} + \frac{\alpha}{2}\norma{u}^2_{L^2(I,L^2(\Omega))}  + \chi_{U_{ad}}(u) - (w,y-S_hu)_{L^2(I,L^2(\Omega))}}_{\mathcal{L}(u,y,w)}\Biggr)
\end{multline}
dove $ \chi_{U_{ad}} $ indica la funzione caratteristica dell'insieme $ U_{ad} $ nel senso dell'analisi convessa, ovvero
\begin{equation}
\chi_{U_{ad}}=
\begin{cases}
0,        &\text{su} U_{ad},\\
\infty   &\text{su} L^2(I,L^2(\Omega))\setminus U_{ad}.
\end{cases}
\end{equation}
Si verifica che $ \phi $ è differenziabile con derivata lipschitziana e fortemente convessa, infatti
\begin{lemma}
\label{phi}
La funzione $ \phi:L^2(I,L^2(\Omega))\to\R $ da ~\eqref{lagr} è fortemente convessa e Frechet-differenziabile con gradiente lipschitziano
\begin{equation}
\nabla\phi(w)=y(w)-S_hu(w),
\end{equation}
dove $ y_h(w)=w+y_d $ e $ u(w)=P_{U_{ad}}(-\frac{1}{\alpha}S^*_hw) $ sono gli unici punti di minimo della lagrangiana $ \mathcal{L}(u,y,w) $ da ~\eqref{lagr} per ogni $ w\in L^2(I,L^2(\Omega)) $ data.
\end{lemma}
Si osservi che, poiché il gradiente $ \nabla\phi(w) $ammette sottogradiente, è possibile applicare una strategia di Newton semi-regolare per il problema duale 
\begin{equation}
\label{P'k}
\min_{w\in L^2(I,L^2(\Omega))} \phi(w).
\end{equation}
Grazie alla forte convessità, il problema \eqref{P'k} ammette un'unica soluzione $ w^* $ che soddisfa $ \nabla\phi(w^*)=0 $.
Una strategia di Newton semi-regolare per ~\eqref{P'k} significa risolvere 
\begin{equation}
\label{newton}
\big( I + \frac{1}{\alpha}S_h\mathbbm{1}_{S^*_hw}S^*_h\big)\delta w=-(w+y_d)+S_hP{U_{ad}}\big( -\frac{1}{\alpha}S^*_hw\big).
\end{equation}
L'equazione ~\eqref{newton} contiene l'operatore $ \mathbbm{1}_{p_h(v)} $ che ha il seguente significato: introdotto l'\textit{inactive set} della funzione $ p_h\in L^2(I,L^2(\Omega)) $ come l'insieme $ \mathcal{I}(p_h)=\Set{\omega\in \Omega\times [0,T] | \big( -\frac{1}{\alpha}p_h(v)\big)(\omega)\in (a(\omega),b(\omega))} $ e $ \mathbbm{1}_{\mathcal{I}(p_h)} $ come la funzione indicatrice 
\begin{equation}
\mathbbm{1}_{\mathcal{I}(p_h)}=
\begin{cases}
1,          &\omega\in\mathcal{I}(p_h), \\
0,          &\omega\in\Omega\times [0,T]\setminus\mathcal{I}(p_h),
\end{cases}
\end{equation}
con $ \mathbbm{1}_{p_h(v)} $ si denota l'endomorfismo auto-aggiunto in $ L^2(I,L^2(\Omega)) $ dato dalla moltiplicazione puntuale con $ \mathbbm{1}_{\mathcal{I}(p_h)} $. Poiché l'Hessiano generalizzato a primo membro di ~\eqref{newton} è un endomorfismo auto-aggiunto e definito positivo, è lecito utilizzare un algoritmo di tipo gradiente coniugato per la computazione del passo di Newton semi-regolare. Anche $ \phi $ è facile da valutare in quanto dal lemma ~\eqref{phi} si evince che 
\begin{equation}
\phi(w)=\frac{1}{2}\norma{w}^2_{L^2(I,L^2(\Omega))} - \frac{\alpha}{2}\norma{u(w)}^2_{L^2(I,L^2(\Omega))} + (w,y_d-S_hu(w))_{L^2(I,L^2(\Omega))}.
\end{equation}


A questo punto è possibile indicare l'algoritmo semi-Newton utilizzato nel presente lavoro:
\begin{algoritmo}
\label{dn}
\begin{enumerate}
\item Inizializzare $ w^0\in L^2(I,L^2(\Omega)) $, $\beta\in(0,1) $, $ k=0 $, 
\item Ripetere fino a convergenza
          \begin{enumerate}
          \item Risolvere l'equazione ~\eqref{newton} per $ \delta w^k $ tramite CG,
          \item Porre $ \lambda:=1 $,
          \item Finché risulta vera la condizione $ \phi(w^k+\lambda\delta w^k) > \phi(w) + \frac{1}{3}\lambda(\nabla\phi(w^k),\delta w^k)_{L^2(I,L^2(\Omega))} $, porre $ \lambda:=\beta\lambda $,
          \item Porre $ w^{k+1}=w^k + \lambda\delta w^k $
         \item Porre $ k:=k+1 $.
          \end{enumerate}
\end{enumerate}
Come criterio di arresto è stato scelto $ \norma{\nabla\phi(w^k)}\le t_0 $, con $ t_0 $ tolleranza prefissata.          
\end{algoritmo}
L'analisi della convergenza del metodo e la plausibilità del criterio di arresto sono affidati al seguente lemma
\begin{lemma}
\label{global}
Sia $ L=1+\norma{S_h}^2 /\alpha $ la costante di Lipschitz di $ \nabla\phi $ e $ \beta\in(0,1) $ come nell'algoritmo  ~\eqref{dn}. Siano $ u_h $ e $ w^* $ le soluzioni di ~\eqref{Pk} e ~\eqref{P'k} rispettivamente. Allora si verifica che 
\begin{enumerate}
\item un passo con parametro di damping $ \lambda\le\beta^{K(L,\beta)} $ è sempre accettato, dove
\begin{equation}
K(L,\beta)=\frac{\log(2)-\log(3L)}{\log(\beta)},
\end{equation}
\item l'algoritmo ~\eqref{dn} converge per qualsiasi dato iniziale $ w^0\in L^2(I,L^2(\Omega)) $, nel senso che $ w\to w^* $, $ u(w)\to u_h $ in $ L^2(I,L^2(\Omega)) $,
\item il criterio di arresto $ \norma{\nabla\phi(w)}_{L^2(I,L^2(\Omega))}\le\text{Toll.} $ è ragionevole poiché
\begin{equation}
\norma{\nabla\phi(w)}_{L^2(I,L^2(\Omega))}\ge \norma{w-w^*}_{L^2(I,L^2(\Omega))}.
\end{equation}
\end{enumerate}
\end{lemma} 


Per completezza si descrive l'algoritmo del gradiente coniugato adoperato per la risoluzione di ~\eqref{newton}
\begin{algoritmo}
\label{cg}
Per brevità sarà indicato con $ A_w $ l'Hessiano generalizzato a primo membro di ~\eqref{newton}, mentre il termine noto a secondo membro con $ b_w $
\begin{enumerate}
\item Inizializzare $ \delta w^0 $ in $ L^2(I,L^2(\Omega)) $, $ r^0:=b_w-A_w\delta w^0 $, $ p^0=r^0 $, $ n:=0 $.
\item Ripetere fino a convergenza
          \begin{enumerate} 
          \item $\alpha^n:=\frac{(r^n,r^n)_{L^2(I,L^2(\Omega))}}{(p^n,A_wp^n)_{L^2(I,L^2(\Omega))}}$,
          \item $\delta w^{n+1}:=\delta w^n + \alpha^np^n$,
          \item $r^{n+1}:=r^n-\alpha^np^n$,
          \item $\beta^n:=\frac{(r^{n+1},r^{n+1})_{L^2(I,L^2(\Omega))}}{(r^n,r^n)_{L^2(I,L^2(\Omega))}}$,
          \item $p^{n+1}:=r^{n+1} + \beta^np^n$,
          \item $k:=k+1$.
          \end{enumerate}
\end{enumerate}
Come criterio di arresto è stato scelto 
\begin{equation}
\norma{r^n}_{L^2(I,L^2(\Omega))}\le t_0 
\label{eq:DNtoll}
\end{equation}
con $ t_0 $ tolleranza prescritta.
E' superfluo specificare che qui l'indice $ n $ denota l'n-esima iterazione di CG, non di Newton.
\label{DN}
\end{algoritmo} 